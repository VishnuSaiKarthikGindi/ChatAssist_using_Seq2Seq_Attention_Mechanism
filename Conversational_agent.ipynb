{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d774c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import re\n",
    "import numpy as np\n",
    "import spacy\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3472f4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download with: python -m spacy download en_core_web_sm\n",
    "spacy_eng = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Preprocess the input text by performing operations such as lowercasing,\n",
    "    removing punctuation, and removing extra whitespace.\n",
    "    \"\"\"\n",
    "    text = text.lower()  # Lowercase the text\n",
    "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", text)  # Remove punctuation\n",
    "    text = re.sub(r\"\\s+\", \" \", text)  # Remove extra spaces\n",
    "    text = text.strip()  # Remove leading and trailing spaces\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a34cee1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, min_freq):\n",
    "        self.itos = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\", 3: \"<UNK>\"}\n",
    "        self.stoi = {v: k for k, v in self.itos.items()}\n",
    "        self.min_freq = min_freq\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.itos)\n",
    "\n",
    "    @staticmethod\n",
    "    def tokenize(text):\n",
    "        return [tok.text.lower() for tok in spacy_eng.tokenizer(text)]\n",
    "\n",
    "    def build_vocab(self, sentences):\n",
    "        freqs = {}\n",
    "        idx = 4\n",
    "        for sentence in sentences:\n",
    "            for word in self.tokenize(sentence):\n",
    "                freqs[word] = freqs.get(word, 0) + 1\n",
    "                if freqs[word] == self.min_freq:\n",
    "                    self.stoi[word] = idx\n",
    "                    self.itos[idx] = word\n",
    "                    idx += 1\n",
    "\n",
    "    def numericalize(self, text):\n",
    "        return [self.stoi.get(token, self.stoi[\"<UNK>\"]) for token in self.tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95859c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QADataset(Dataset):\n",
    "    def __init__(self, file_path, min_freq=5):\n",
    "        self.df = pd.read_csv(file_path)\n",
    "        self.questions = self.df[\"question\"].apply(clean_text)\n",
    "        self.answers = self.df[\"answer\"].apply(clean_text)\n",
    "        self.vocab = Vocab(min_freq)\n",
    "        self.vocab.build_vocab(self.questions.tolist() + self.answers.tolist())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        question = self.questions.iloc[idx]\n",
    "        answer = self.answers.iloc[idx]\n",
    "\n",
    "        question_ids = [self.vocab.stoi[\"<SOS>\"]] + self.vocab.numericalize(question) + [self.vocab.stoi[\"<EOS>\"]]\n",
    "        answer_ids = [self.vocab.stoi[\"<SOS>\"]] + self.vocab.numericalize(answer) + [self.vocab.stoi[\"<EOS>\"]]\n",
    "\n",
    "        return torch.tensor(question_ids), torch.tensor(answer_ids)\n",
    "    \n",
    "class BatchCollator:\n",
    "    def __init__(self, pad_idx):\n",
    "        self.pad_idx = pad_idx\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        questions, answers = zip(*batch)\n",
    "        questions_padded = pad_sequence(questions, batch_first=False, padding_value=self.pad_idx)\n",
    "        answers_padded = pad_sequence(answers, batch_first=False, padding_value=self.pad_idx)\n",
    "        return questions_padded, answers_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f591c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(file_path, batch_size=32, num_workers=8, shuffle=True, pin_memory=True):\n",
    "    dataset = QADataset(file_path)\n",
    "    pad_idx = dataset.vocab.stoi[\"<PAD>\"]\n",
    "    \n",
    "    loader = DataLoader(dataset, \n",
    "                        batch_size=batch_size,\n",
    "                        num_workers=num_workers,\n",
    "                        shuffle=shuffle,\n",
    "                        pin_memory=pin_memory,\n",
    "                        collate_fn=BatchCollator(pad_idx))\n",
    "    \n",
    "    return loader, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97de55f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Implementation of Encoder and decoder architecture using the context vectors for attention mechanism\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, bidirectional=True, dropout=dropout)\n",
    "        #self.fc_hidden = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        #self.fc_cell = nn.Linear(hidden_size * 2, hidden_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        encoder_outputs, (hidden, cell) = self.lstm(x)\n",
    "        #hidden = self.fc_hidden(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n",
    "        #cell = self.fc_cell(torch.cat((cell[-2,:,:], cell[-1,:,:]), dim=1))\n",
    "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1).unsqueeze(0)\n",
    "        cell = torch.cat((cell[-2,:,:], cell[-1,:,:]), dim=1).unsqueeze(0)\n",
    "        return encoder_outputs, hidden, cell\n",
    "    \n",
    "\"\"\"\n",
    "#Implementation using BERT for better semantic understanding\n",
    "class ContextualEncoder(nn.Module):\n",
    "    def __init__(self, hidden_size, num_layers, p):\n",
    "        super(ContextualEncoder, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.lstm = nn.LSTM(self.bert.config.hidden_size, hidden_size, num_layers, bidirectional=True, dropout=dropout)\n",
    "        #self.fc_hidden = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        #self.fc_cell = nn.Linear(hidden_size * 2, hidden_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            outputs = self.bert(x)\n",
    "        encoder_outputs = outputs.last_hidden_state\n",
    "        hidden, cell = self.lstm(encoder_states)\n",
    "        hidden = self.fc_hidden(torch.cat((hidden[0:1], hidden[1:2]), dim=2))\n",
    "        cell = self.fc_cell(torch.cat((cell[0:1], cell[1:2]), dim=2))\n",
    "        return encoder_outputs, hidden, cell\n",
    "\"\"\"\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, output_size, num_layers, dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.lstm = nn.LSTM(hidden_size*2 + embed_size, hidden_size, num_layers, dropout=dropout)\n",
    "        self.attention = nn.Linear(hidden_size*3, 1)\n",
    "        self.fc_out = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, encoder_outputs, hidden, cell):\n",
    "        x = x.unsqueeze(0)\n",
    "        embed = self.dropout(self.embedding(x))\n",
    "        sequence_length = encoder_outputs.shape[0]\n",
    "        h_reshaped = hidden.repeat(sequence_length, 1, 1)\n",
    "        energy = torch.tanh(self.attention(torch.cat((h_reshaped, encoder_outputs), dim=2)))\n",
    "        attention_weights = torch.softmax(energy, dim=0)\n",
    "        context_vector = torch.einsum(\"snk,snl->knl\", attention_weights, encoder_outputs)\n",
    "        lstm_input = torch.cat((context_vector, embed), dim=2)\n",
    "        outputs, (hidden, cell) = self.lstm(lstm_input, (hidden, cell))\n",
    "        predictions = self.fc_out(outputs).squeeze(0)\n",
    "        return predictions, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39258af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Implementation of Sequence to Sequence model using LSTM cells \n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        batch_size = src.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.fc_out.out_features\n",
    "\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(src.device)\n",
    "        encoder_outputs, hidden, cell = self.encoder(src)\n",
    "\n",
    "        x = trg[0]\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, cell = self.decoder(x, encoder_outputs, hidden, cell)\n",
    "            outputs[t] = output\n",
    "            best_guess = output.argmax(1)\n",
    "            x = trg[t] if torch.rand(1).item() < teacher_forcing_ratio else best_guess\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a9dd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "epochs=100\n",
    "lr=3e-4\n",
    "embed_size=300\n",
    "hidden_size=1024\n",
    "num_layers=1\n",
    "dropout=0.5\n",
    "batch_size=32\n",
    "\n",
    "# Initialize and Train the Model\n",
    "def train(qa_file, epochs=epochs, lr=lr, embed_size=embed_size, hidden_size=hidden_size, num_layers=num_layers, dropout=dropout, batch_size=batch_size, num_workers=8, shuffle=True, pin_memory=True):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    data_loader, dataset = create_data_loader(qa_file, batch_size=batch_size, num_workers=num_workers, shuffle=shuffle, pin_memory=pin_memory)\n",
    "\n",
    "    input_size = len(dataset.vocab)\n",
    "    output_size = len(dataset.vocab)\n",
    "\n",
    "    encoder = Encoder(input_size, embed_size, hidden_size, num_layers, dropout).to(device)\n",
    "    decoder = Decoder(input_size, embed_size, hidden_size, output_size, num_layers, dropout).to(device)\n",
    "    model = Seq2Seq(encoder, decoder).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    pad_idx = dataset.vocab.stoi[\"<PAD>\"]\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for batch in data_loader:\n",
    "            questions, answers = batch\n",
    "            questions, answers = questions.to(device), answers.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(questions, answers)\n",
    "            output = output[1:].view(-1, output.shape[-1])\n",
    "            answers = answers[1:].reshape(-1)\n",
    "            loss = criterion(output, answers)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "\n",
    "train(\"path/to/your/qa_dataset.csv\")\n",
    "        \n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot training and validation losses\n",
    "plt.plot(range(1, epochs + 1), train_losses, label='Train')\n",
    "#plt.plot(range(1, epochs + 1), val_losses, label='Validation')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e28399",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.save(\"encoder_final\")\n",
    "decoder.save(\"decoder_final\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
